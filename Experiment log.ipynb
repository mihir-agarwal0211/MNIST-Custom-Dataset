{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23b4dfe3",
   "metadata": {},
   "source": [
    "## Experiment Log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b292ee9",
   "metadata": {},
   "source": [
    "### 1st) splitting the data in test and train -\n",
    "following is the code which solved my problem, i had to go through basic python codes and write it myself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2722d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.listdir('/content/drive/MyDrive/IIITD/train/')\n",
    "root_dir = '/content/drive/MyDrive/IIITD/train/'\n",
    "for cls in train_dir:\n",
    "  src = root_dir + cls\n",
    "  allFileNames = os.listdir(src)\n",
    "  print(allFileNames)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a794902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.listdir('/content/drive/MyDrive/IIITD/data')\n",
    "root_dir = '/content/drive/MyDrive/IIITD/'\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.05\n",
    "for cls in train_dir: \n",
    "# Creating partitions of the data after shuffeling\n",
    "  src = root_dir+ 'data/' + cls # Folder to copy images from\n",
    "\n",
    "  allFileNames = os.listdir(src)\n",
    "  np.random.shuffle(allFileNames)\n",
    "  train_FileNames, val_FileNames, test_FileNames = np.split(np.array(allFileNames),\n",
    "                                                            [int(len(allFileNames)* (1 - (val_ratio + test_ratio))), \n",
    "                                                            int(len(allFileNames)* (1 - test_ratio))])\n",
    "\n",
    "  train_FileNames = [src+'/'+ name for name in train_FileNames.tolist()]\n",
    "  val_FileNames = [src+'/' + name for name in val_FileNames.tolist()]\n",
    "  test_FileNames = [src+'/' + name for name in test_FileNames.tolist()]\n",
    "\n",
    "  print('Total images: ', len(allFileNames))\n",
    "  print('Training: ', len(train_FileNames))\n",
    "  print('Validation: ', len(val_FileNames))\n",
    "  print('Testing: ', len(test_FileNames))\n",
    "\n",
    "  # Copy-pasting images\n",
    "  for name in train_FileNames:\n",
    "      shutil.copy(name, root_dir +'train/' + cls)\n",
    "\n",
    "  for name in val_FileNames:\n",
    "      shutil.copy(name, root_dir +'valid/' + cls)\n",
    "\n",
    "  for name in test_FileNames:\n",
    "      shutil.copy(name, root_dir +'test/' + cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42ae83d",
   "metadata": {},
   "source": [
    "## 2nd) Converting Images to GrayScale\n",
    "### I first wrote a function to reads an image, convort it to gray scale and then save it back to the same directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b93c889",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.listdir('/content/drive/MyDrive/IIITD/data/')\n",
    "\n",
    "root_dir = '/content/drive/MyDrive/IIITD/'\n",
    "# os.makedirs(root_dir + '/train')\n",
    "for cls in train_dir:\n",
    "  src = root_dir+ 'data/' + cls\n",
    "  allFileNames = os.listdir(src)\n",
    "  # print(allFileNames)\n",
    "  # print(src + '/'+ allFileNames)\n",
    "  for img in allFileNames:\n",
    "    IMG_LOC=src+'/'+img\n",
    "    image = io.imread(IMG_LOC)\n",
    "    gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    cv.imwrite(IMG_LOC,gray_image)\n",
    "    # print(gray_image)\n",
    "    # print(\"-----\")\n",
    "    # print(img) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41b6c80",
   "metadata": {},
   "source": [
    "### But when i was reading them with cv2, it was again coming as a RGB image, then i found that i can directly read them as gratscale, so i wrote the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d76db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.listdir(r'E:\\Internship\\IIITD MIDAS\\Task 3\\Dataset')\n",
    "root_dir = r'E:\\Internship\\IIITD MIDAS\\Task 3\\Dataset'\n",
    "X = []\n",
    "f=0\n",
    "for cls in train_dir:\n",
    "  src = root_dir +'\\\\'+ cls\n",
    "  allFileNames = os.listdir(src)\n",
    "  a = cls\n",
    "  a = a[-2:]\n",
    "  p = int(a)\n",
    "  p\n",
    "  # print(cls)\n",
    "  # # print(src + '/'+ allFileNames)\n",
    "  \n",
    "  for img in allFileNames:\n",
    "    # ytrain.append(p)\n",
    "    IMG_LOC=src+'\\\\'+img\n",
    "    # image = io.imread(IMG_LOC)\n",
    "    image=cv.imread(IMG_LOC, cv.IMREAD_GRAYSCALE)\n",
    "    image=cv.resize(image,(28,28))\n",
    "    print(f)\n",
    "    f=f+1\n",
    "    # testing_data.append([np.array(img),img_num])\n",
    "    X.append([np.array(image),np.array(p)])\n",
    "  # print(X)\n",
    "  # print(ytrain)\n",
    "    # print(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec78a54",
   "metadata": {},
   "source": [
    "### 3)Shape of the Images\n",
    "\n",
    "My model was throwing error about the size of the input, then later i figured out that i had to resize the images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f5eb2b",
   "metadata": {},
   "source": [
    "### 4)Loss function\n",
    "I was using the \"sparse_categorical_crossentropy\" loass function which was giving some error, i finally solved my problem by using \"categorical_crossentropy\" loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a00e0e",
   "metadata": {},
   "source": [
    "### 5) Saving the model\n",
    "I was not able to save the model and re load the weights, but found the soulution by spening some time on google\n",
    "following is the code - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55379628",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"E:\\Internship\\IIITD MIDAS\\Task 2.2-MNIST\\checkpoints\\cp-{epoch:04d}.ckpt\"\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    save_freq=20,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0583b518",
   "metadata": {},
   "source": [
    "### 6) Deciding the layers of Convolution Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e18aac",
   "metadata": {},
   "source": [
    "### 7) Plotting Confusion matrix\n",
    "finding quality metrics for a categorical Classification data was a little hard for me\n",
    "\n",
    "Although i finally plotted the confusion matrix using the following code,which can be used to get the precision, recall and F2 score as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb2a1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at confusion matrix \n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(x_test)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(y_test,axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(10)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
